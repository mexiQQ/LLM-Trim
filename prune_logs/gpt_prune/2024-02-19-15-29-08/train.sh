python hf_prune_gpt2_layerwise.py --base_model openai-community/gpt2 --device cuda --eval_device cuda --block_mlp_layer_start 11 --block_mlp_layer_end 12 --block_attention_layer_start 11 --block_attention_layer_end 12 --pruning_ratio_attn 0.25 --pruning_ratio_mlp 0.2 --kq_mode qr_pivot --seed 42 --num_examples 64 --max_seq_len 1024 --test_after_prune --prune_attn --prune_mlp